{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "alt.data_transformers.enable('json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denver = pd.read_csv('https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_denver/dwellings_denver.csv')\n",
    "\n",
    "dwellings_ml = pd.read_csv(\"https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_ml/dwellings_ml.csv\")\n",
    "\n",
    "neighborhood = pd.read_csv(\"https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_neighborhoods_ml/dwellings_neighborhoods_ml.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 2-3 charts that evaluate potential relationships between the house variables and the variable before1980 Explain what you learn from the charts that could help a machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create T/F column for before 1980\n",
    "denver['before1980'] = denver.yrbuilt < 1980\n",
    "\n",
    "avgdata = denver.groupby('before1980').agg(avg_netprice = ('netprice', np.mean)).reset_index()\n",
    "denver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netprice = (alt.Chart(denver)\n",
    "    .mark_circle()\n",
    "    .encode(\n",
    "        alt.X('yrbuilt', scale = alt.Scale(zero = False),\n",
    "        axis =alt.Axis(format = 'd')),\n",
    "        alt.Y('netprice', axis = alt.Axis(title= 'Net Price ($)')))\n",
    "        .properties(\n",
    "        height = 150,\n",
    "        width = 400,\n",
    "        title = {'text': \"Net Prices relation with Year Built\"})\n",
    ")\n",
    "\n",
    "netprice.save('netprice.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot seems to be a jumbled mess. It is hard to tell if there is any real telling details between the net price of a home and the year it was built. Of note, there were many more homes after 1980 with drastically high net prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "livearea = (alt.Chart(denver)\n",
    "    .mark_circle()\n",
    "    .encode(\n",
    "        alt.X('yrbuilt', scale = alt.Scale(zero = False),\n",
    "        axis =alt.Axis(format = 'd')),\n",
    "        alt.Y('livearea', axis = alt.Axis(title= 'Liveable Area (ft.)')))\n",
    "        .properties(\n",
    "        height = 150,\n",
    "        width = 400,\n",
    "        title = {'text': \"Livable Areas relation with Year Built\"})\n",
    ")\n",
    "\n",
    "livearea.save('livearea.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classification model labeling houses as being built “in or before 1980” or “after 1980”. Your goal is to reach 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob1 = train_test_split(dwellings_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize Data for Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = dwellings_ml.before1980\n",
    "features = dwellings_ml.drop(columns=['before1980', 'yrbuilt', 'parcel'])\n",
    "#features = dwellings_ml.filter(['nocars', 'numbaths'])\n",
    "#features = dwellings_ml.filter(['livearea', 'basement', 'stories', 'nocars', 'numbaths'])\n",
    "\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(\n",
    "    features, \n",
    "    targets, \n",
    "    test_size = .3, \n",
    "    random_state = 24601) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.664969450101833"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierGNB = GaussianNB()\n",
    "\n",
    "classifierGNB.fit(features_train, targets_train)\n",
    "\n",
    "targets_predicted = classifierGNB.predict(features_test)\n",
    "\n",
    "targets_test\n",
    "targets_predicted\n",
    "metrics.accuracy_score(targets_test, targets_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8945301134710504"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierDT = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "classifierDT.fit(features_train, targets_train)\n",
    "\n",
    "targets_predicted = classifierDT.predict(features_test)\n",
    "\n",
    "metrics.accuracy_score(targets_test, targets_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierRF = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "classifierRF.fit(features_train, targets_train)\n",
    "\n",
    "targets_predicted = classifierRF.predict(features_test)\n",
    "\n",
    "metrics.accuracy_score(targets_test, targets_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2\n",
    "\n",
    "MY random model was a Random Forest with 10 estimators. Reached 92% accuracy. My targets was the dwelling denver data with 'before1980', 'yrbuilt', 'parcel' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justify your classification model by discussing the most important features selected by your model. This discussion should include a chart and a description of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierRF.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame({'features':features.columns, 'importance':classifierRF.feature_importances_})\n",
    "top10 = feature_df[feature_df['importance'] >= 0.045].sort_values('importance', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "### plot of features and importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10features = (alt.Chart(top10)\n",
    ".mark_bar()\n",
    ".encode(x = 'importance',\n",
    "        y = 'features')\n",
    ")\n",
    "top10features.save('top10.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(classifierRF, features_test, targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2334 +3968) /6874\n",
    "\n",
    "recall = 3968/(3968+325)\n",
    "recall #0.92429\n",
    "\n",
    "precision = 3968/(3968+247)\n",
    "precision #0.94139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.balanced_accuracy_score(targets_test, targets_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(targets_test, targets_predicted))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "987e2da346832099133f2da5dc1d8315b76c332f69043c1b3db793da68c4c466"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
