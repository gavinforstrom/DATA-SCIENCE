{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/fivethirtyeight/data/raw/master/star-wars-survey/StarWars.csv'\n",
    "\n",
    "sw_questions = pd.read_csv(url, encoding = 'ISO-8859-1', header=None, nrows=2)\n",
    "sw_responses = pd.read_csv(url, encoding = 'ISO-8859-1', header=None, skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = (sw_questions.iloc[0,:]\n",
    ".replace(\"Have you seen any of the 6 films in the Star Wars franchise?\", \"have_seen_any\")\n",
    ".replace(\"Do you consider yourself to be a fan of the Star Wars film franchise?\",\"fan_sw\")\n",
    ".replace(\"Which of the following Star Wars films have you seen? Please select all that apply.\",\"seen_\")\n",
    ".replace(\"Please rank the Star Wars films in order of preference with 1 being your favorite film in the franchise and 6 being your least favorite film.\",\"rank_\")\n",
    ".replace(\"Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her.\",\"view\")\n",
    ".replace(\"Which character shot first?\", \"shotfirst\")\n",
    ".replace(\"Are you familiar with the Expanded Universe?\",\"familiar_eu\")\n",
    ".replace(\"Do you consider yourself to be a fan of the Expanded Universe?æ\",\"fan_eu\")\n",
    ".replace(\"Do you consider yourself to be a fan of the Star Trek franchise?\", \"fan_st\")\n",
    ".str.lower()\n",
    ".str.replace(\" \", \"_\")\n",
    ".ffill()\n",
    ")\n",
    "\n",
    "question_2 = (sw_questions.iloc[1,:]\n",
    ".replace(\"Response\",\"\")\n",
    ".str.replace(\"Star Wars: Episode\", \"\")\n",
    ".str.lower()\n",
    ".str.replace(\" \",\"_\")\n",
    ".fillna(\"\")\n",
    ")\n",
    "\n",
    "\n",
    "column_names = question_1 + question_2\n",
    "\n",
    "print(column_names.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_responses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hanshotfirst = sw_responses.shotfirst.value_counts(normalize=True).reset_index()\n",
    "hanshotfirst[\"percent\"] = round(hanshotfirst.shotfirst*100, 0)\n",
    "\n",
    "hanshotfirst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Validating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent men who have seen at least one film\n",
    "print((sw_responses.query('gender == \"Male\"')\n",
    ".have_seen_any\n",
    ".value_counts(normalize=True)).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent women\n",
    "print((sw_responses.query('gender == \"Female\"')\n",
    ".have_seen_any\n",
    ".value_counts(normalize=True)).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched = sw_responses.filter(regex=\"^seen_\").dropna(how=\"all\")\n",
    "len(watched)\n",
    "watched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_percent = round(watched.notnull().sum() / len(watched), 2).reset_index(name=\"percent\")\n",
    "watched_percent[\"percentfull\"] = round(watched_percent.percent*100, 0)\n",
    "watched_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please validate that the data provided on GitHub lines up with the article by recreating 2 of their visuals and calculating 2 summaries that they report in the article.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "bars = alt.Chart(watched_percent).mark_bar().encode(\n",
    "     x = alt.X('percent', axis = None),\n",
    "     y = alt.Y('index', axis=alt.Axis(title = \"\")))\n",
    "    \n",
    "    \n",
    "text = bars.mark_text(align='left', baseline='middle', dx=3\n",
    ").encode(text = 'percentfull')\n",
    "\n",
    "\n",
    "(bars + text).properties(\n",
    "    height = 400,\n",
    "    width = 800,\n",
    "    title = {'text': \"Which Star Wars Movies Have You Seen\", 'subtitle': \"According to 835 respondents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "bars = alt.Chart(hanshotfirst).mark_bar().encode(\n",
    "     x = alt.X('shotfirst', axis = None),\n",
    "     y = alt.Y('index', axis=alt.Axis(title = \"\")))\n",
    "    \n",
    "    \n",
    "text = bars.mark_text(align='left', baseline='middle', dx=3\n",
    ").encode(text = 'percent')\n",
    "\n",
    "\n",
    "(bars + text).properties(\n",
    "    height = 400,\n",
    "    width = 800,\n",
    "    title = {'text': \"Who Shot First\", 'subtitle': \"According to 834 respondents\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the dataset to respondents that have seen at least one film.\n",
    "\n",
    "q3 = sw_responses.query('have_seen_any == \"Yes\"')\n",
    "print(q3.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column that converts the age ranges to a single number. Drop the age range categorical column.\n",
    "\n",
    "ml_age = (q3.age\n",
    "    .str.split(\"-\", expand= True)\n",
    "    .rename(columns = {0:'age_min', 1:'age_max'})\n",
    "    .apply(lambda x: x.str.replace(\"> \", \"\"))\n",
    "    .astype('float')\n",
    "    .age_min\n",
    "    )\n",
    "\n",
    "print(ml_age.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column that converts the school groupings to a single number. Drop the school categorical column.\n",
    "ml_school = (q3.education.\n",
    "        str.replace('Less than high school degree', '9').\n",
    "        str.replace('High school degree', '12').\n",
    "        str.replace('Some college or Associate degree', '14').\n",
    "        str.replace('Bachelor degree', '16').\n",
    "        str.replace('Graduate degree', '20').\n",
    "        astype('float'))\n",
    "\n",
    "print(ml_school.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column that converts the income ranges to a single number. Drop the income range categorical column.\n",
    "ml_income = (q3.household_income\n",
    "    .str.replace(\"\\$|,|\\+\", \"\")\n",
    "    .str.split(\"-\", expand=True)\n",
    "    .rename(columns = {0:'income_min', 1:'income_max'})\n",
    "    .astype('float')\n",
    "    .income_min\n",
    ")\n",
    "\n",
    "print(ml_income.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encode all remaining categorical columns.\n",
    "ml_onehot = pd.get_dummies(q3.filter(['fan_sw', 'seen__i__the_phantom_menace',\n",
    "       'seen__ii__attack_of_the_clones', 'seen__iii__revenge_of_the_sith',\n",
    "       'seen__iv__a_new_hope', 'seen__v_the_empire_strikes_back',\n",
    "       'seen__vi_return_of_the_jedi', 'viewhan_solo', 'viewluke_skywalker',\n",
    "       'viewprincess_leia_organa', 'viewanakin_skywalker',\n",
    "       'viewobi_wan_kenobi', 'viewemperor_palpatine', 'viewdarth_vader',\n",
    "       'viewlando_calrissian', 'viewboba_fett', 'viewc-3p0', 'viewr2_d2',\n",
    "       'viewjar_jar_binks', 'viewpadme_amidala', 'viewyoda', 'shotfirst',\n",
    "       'familiar_eu', 'fan_eu', 'fan_st', 'gender', 'age', 'household_income',\n",
    "       'education', 'location_(census_region)']), drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create your target (also known as \"y\" or \"label\") column based on the new income range column.\n",
    "# combine all the new columns into a machine learning dataset\n",
    "starwars_ml = pd.concat([ml_onehot, \n",
    "                         q3.filter(['rank_i__the_phantom_menace', 'rank_ii__attack_of_the_clones',\n",
    "                                    'rank_iii__revenge_of_the_sith', 'rank_iv__a_new_hope',\n",
    "                                    'rank_v_the_empire_strikes_back', 'rank_vi_return_of_the_jedi']),\n",
    "                         ml_age, \n",
    "                         ml_school, \n",
    "                         ml_income], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = starwars_ml.drop(['income_min'], axis=1)\n",
    "\n",
    "target = (starwars_ml.income_min >= 50000) *1\n",
    "\n",
    "target.value_counts()\n",
    "\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(\n",
    "    features, \n",
    "    target, \n",
    "    test_size = .3, \n",
    "    random_state = 24601) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierGNB = GaussianNB()\n",
    "\n",
    "classifierGNB.fit(features_train, targets_train)\n",
    "\n",
    "targets_predicted = classifierGNB.predict(features_test)\n",
    "\n",
    "targets_test\n",
    "targets_predicted\n",
    "metrics.accuracy_score(targets_test, targets_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierDT = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "classifierDT.fit(features_train, targets_train)\n",
    "\n",
    "targets_predicted = classifierDT.predict(features_test)\n",
    "\n",
    "metrics.accuracy_score(targets_test, targets_predicted)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "987e2da346832099133f2da5dc1d8315b76c332f69043c1b3db793da68c4c466"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
